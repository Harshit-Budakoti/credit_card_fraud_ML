name: Install Dependencies and Set Up Environment

on: [push]

jobs:
  setup:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install git
      run: |
        sudo apt-get update
        sudo apt-get install git

    - name: Clone DagsHub repository
      run: |
        git clone https://dagshub.com/harshitbudakotimatsc20/credit_card_fraud_ML.git
    - name: Install Java JDK
      run: |
        sudo apt-get update --fix-missing
        sudo apt-get install openjdk-8-jdk-headless -qq > /dev/null

    - name: Install Spark
      run: |
        wget -q https://archive.apache.org/dist/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz
        tar -xvf spark-3.5.1-bin-hadoop3.tgz

    - name: Install Python dependencies
      run: |
        pip install -q findspark
        pip install pyspark==3.5.1

    - name: Run transformation scripts
      run: |
        python s3://credit_card_fraud_ML/preprocessingofdata.py ${{ secrets.DATASET1_PATH }} ${{ secrets.DATASET2_PATH }}
        python s3://credit_card_fraud_ML/encodingoftestdata.py ${{ secrets.DATASET3_PATH }} ${{ secrets.DATASET4_PATH }}

    - name: Load model and make predictions
      run: python s3://credit_card_fraud_ML/predictions.py ${{ secrets.DATASET5_PATH }}
      env:
        MLFLOW_TRACKING_URI: https://dagshub.com/harshitbudakotimatsc20/credit_card_fraud_ML.mlflow
        MLFLOW_S3_ENDPOINT_URL: https://dagshub.com/harshitbudakotimatsc20/credit_card_fraud_ML.dvc
        DAGSHUB_ACCESS_KEY_ID: ${{ secrets.DAGSHUB_ACCESS_KEY }}
